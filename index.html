<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <br>
    <div class="logo" style="text-align: center; width: 5%;">
        <a href="index.html">
            <img src="./assets/images/mirage.png">
        </a>
    </div>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills">
    <title>Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills</title>
    <script>

    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills</h1>
                        
                        <span class="author-block">
                            <a target="_blank"
                                href="https://scholar.google.com/citations?user=KO77A2oAAAAJ&hl=en">Yuquan&#160;Xie</a><sup>1
                            </sup>,
                            <a target="_blank"
                                href="https://scholar.google.com/citations?user=TDBF2UoAAAAJ&hl=en&oi=ao">Zaijing&#160;Li</a><sup>1
                                2</sup>,
                            <a target="_blank"
                                href="https://scholar.google.com/citations?user=9Vc--XsAAAAJ&hl=en&oi=ao">Rui&#160;Shao</a><sup>1&#9993</sup>,
                            <a target="_blank"
                                href="https://scholar.google.com/citations?user=Mpg0w3cAAAAJ&hl=en&oi=ao">Gongwei&#160;Chen</a><sup>1</sup>,
                            <br>
                            <a target="_blank"
                                href="https://scholar.google.com/citations?hl=en&user=Awsue7sAAAAJ">Dongmei&#160;Jiang</a><sup>2</sup>,
                            <a target="_blank"
                                href="https://scholar.google.com/citations?hl=en&user=nHmlZ5QAAAAJ">Kaiwen&#160;Zhou</a><sup>3</sup>,
                            <a target="_blank"
                                href="https://scholar.google.com/citations?user=M6YfuCTSaKsC&hl=en">Yinchuan&#160;Li</a><sup>3</sup>,
                            <a target="_blank"
                                href="https://scholar.google.com/citations?hl=en&user=yywVMhUAAAAJ">Liqiang&#160;Nie</a><sup>1&#9993</sup>,
                            <div class="is-size-5 publication-authors" style="font-size: 10px;">
                                <span class="author-block"><sup>1</sup>Harbin Institute of Technology,
                                    Shenzhen&#160&#160&#160</span>
                                <span class="author-block"><sup>2</sup>Peng Cheng Laboratory&#160&#160&#160</span>
                                <span class="author-block"><sup>3</sup>Huawei Noah's Ark Lab</span>
                            </div>


                            <div class="is-size-5 publication-authors" style="font-size: 10px;">
                                <span class="author-block"><sup>&#9993&#160;</sup>Corresponding
                                    author&#160;&#160;</span>
                            </div>
                            <div class="column has-text-centered">
                                <div class="publication-links">
                                    <span class="link-block">
                                        <a target="_blank" href="https://arxiv.org/abs/2502.19902"
                                            class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="ai ai-arxiv"></i>
                                            </span>
                                            <span>arXiv</span>
                                        </a>
                                    </span>

                                    <span class="link-block">
                                        <a target="_blank" href="https://arxiv.org/pdf/2502.19902"
                                            class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fas fa-file-pdf"></i>
                                            </span>
                                            <span>PDF</span>
                                        </a>
                                    </span>
                                    <!-- Code Link. -->
                                    <span class="link-block">
                                        <a target="_blank" href="https://github.com/JiuTian-VL/Mirage-1"
                                            class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fab fa-github"></i>
                                            </span>
                                            <span>Code</span>
                                        </a>
                                    </span>
                                    <br />

                                </div>

                            </div>
                    </div>

                </div>
            </div>
        </div>
    </section>

   
    <section class="section" style="background-color:#efeff081">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p style="font-size: 125%">
                           Recent efforts to leverage the Multi-modal Large Language Model (MLLM) as GUI agents have yielded 
                            promising outcomes. However, these agents still struggle with long-horizon tasks in online environments, 
                            primarily due to insufficient knowledge and the inherent gap between offline and online domains. 
                            In this paper, inspired by how humans generalize knowledge in open-ended environments, we propose a 
                            <b>H</b>ierarchical <b>M</b>ultimodal <b>S</b>kills (<b>HMS</b>) module to tackle the issue of insufficient knowledge. 
                            It progressively abstracts trajectories into execution skills, core skills, and ultimately meta-skills, providing a hierarchical 
                            knowledge structure for long-horizon task planning. To bridge the domain gap, we propose 
                            the <b>S</b>kill-<b>A</b>ugmented <b>M</b>onte <b>C</b>arlo <b>T</b>ree <b>S</b>earch (<b>SA-MCTS</b>) 
                            algorithm, which efficiently leverages skills acquired in offline environments to reduce the action search space during 
                            online tree exploration. Building on HMS, we propose <b>Mirage-1</b>, a multimodal, cross-platform, plug-and-play GUI agent. 
                            To validate the performance of Mirage-1 in real-world long-horizon scenarios, we constructed a new benchmark, 
                            AndroidLH. Experimental results show that Mirage-1 outperforms previous agents by 32\%, 19\%, 15\%, and 79\% on AndroidWorld, 
                            MobileMiniWob++, Mind2Web-Live, and AndroidLH, respectively. 
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

   


    <section class="section" style="background-color:#ffffff">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3">Overview Framework</h2>
                        <img src="assets/images/fig1.png" class="interpolation-image" alt=""
                            style="display: block; margin-left: auto; margin-right: auto" width="800" height="700" />
                        <br>
                        <span style="font-size: 110%">
                            The Mirage-1 framework comprises a Hierarchical Planner, an Operator, a Decision Reflector, 
                            and a Hierarchical Multimodal Skills Module (HMS). To bridge the offline-online domain gap, 
                            Skill-Augmented Monte Carlo Tree Search (SA-MCTS) is employed for unseen task exploration, 
                            with successful trajectories expanding HMS capabilities. The Hierarchical Planner retrieves Core 
                            Skills from HMS and decomposes task goals into sub-goals for Operator execution. 
                            The Decision Reflector leverages Execution Skills to assess task execution feasibility.</span>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- result -->
    <section class="section" style="background-color:#efeff081">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Experiment</span></h2>
                        <h1><span class="dvima">Table1: Performance comparison on AndroidWorld, MobileMiniWob++, and AndroidLH. </span></h1>
                        <img src="assets/images/table1.png" class="interpolation-image" alt="" width="500" height="250"
                            style="display: block; margin-left: auto; margin-right: auto" />
                        <br>
                    </div>
                </div>

            </div>
        </div>
    </section>

    <!--Conclusion-->
    <section class="section" style="background-color:#ffffff">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Conclusion</span></h2>

                        <p style="font-size: 125%">
                            In this paper, we propose a Hierarchical Multimodal Skills module (HMS) that 
                            addresses the challenge of insufficient prior knowledge in long-horizon task planning. 
                            To address the domain gap between offline and online, a Skill-Augmented Monte Carlo Tree 
                            Search (SA-MCTS) algorithm is proposed. This algorithm effectively utilizes offline-acquired 
                            skills to reduce the action search space during online tree exploration. On top of HMS, 
                            we propose multimodal agent Mirage-1. Experimental results demonstrate that Mirage-1 
                            achieves superior performance compared to SOTA GUI agents, particularly in long-horizon tasks.
                        </p>

                    </div>
                </div>

            </div>
        </div>
    </section>


</body>

</html>
